@article{wang2022IEEEComput.Archit.Lett.,
  title = {Characterization and {{Implementation}} of {{Radar System Applications}} on a {{Reconfigurable Dataflow Architecture}}},
  author = {Wang, Yinshen and Li, Wenming and Liu, Tianyu and Zhou, Liangjiang and Wang, Bingnan and Fan, Zhihua and Ye, Xiaochun and Fan, Dongrui and Ding, Chibiao},
  year = {2022},
  month = jul,
  journal = {IEEE Computer Architecture Letters},
  volume = {21},
  number = {2},
  pages = {121--124},
  issn = {1556-6064},
  doi = {10.1109/lca.2022.3215595},
  abstract = {The fast developed and widely used radar system techniques call for novel solutions on hardware design. Under a massive data source and the real-time requirements in radar signal processing scenarios (e.g., Synthetic Aperture Radar (SAR)), reconfigurable dataflow architecture is considered as a promising solution. In this article, we first extract the typical algorithms in radar systems and characterize their dataflow manners. Then a reconfigurable dataflow architecture is proposed, with high width SIMD extended PE. The application implementations with mapping strategy and workflow are shown to reach high hardware utilization and efficient data supply. Our work achieves \$8 {\textbackslash}times\$8{\texttimes} and \$5.3{\textbackslash}times\$5.3{\texttimes} energy efficiency improvement over DSP and GPU (NVIDIA Tesla V100), respectively, on large scale FFT, as well as high performance. Under actual scene of \$8K {\textbackslash}times 8K\$8K{\texttimes}8K SAR imaging baseline, it gets \$9.4 {\textbackslash}times\$9.4{\texttimes} speedup over a six-core CPU.},
  copyright = {All rights reserved},
  langid = {american},
  keywords = {Computer architecture,dataflow architecture,Hardware,Radar,Radar applications,Radar imaging,Radar polarimetry,Reconfigurable hardware,Synthetic aperture radar},
  annotation = {0 citations (Crossref) [2023-07-14] [ZMU-dateModified]2023-10-13T11:51:42+08:00},
  file = {/Users/liutianyu/Documents/Amy's Library/AMS/Wang et al_2022_Characterization and Implementation of Radar System Applications on a_IEEE Computer Architecture Letters.pdf;/Users/liutianyu/Zotero/storage/LGGDCTV7/9924542.html}
}
@article{fan2023IEEETrans.ParallelDistrib.Syst.,
  title = {Accelerating {{Convolutional Neural Networks}} by {{Exploiting}} the {{Sparsity}} of {{Output Activation}}},
  author = {Fan, Zhihua and Li, Wenming and Wang, Zhen and Liu, Tianyu and Wu, Haibin and Liu, Yanhuan and Wu, Meng and Wu, Xinxin and Ye, Xiaochun and Fan, Dongrui and Sun, Ninghui and An, Xuejun},
  year = {2023},
  month = dec,
  journal = {IEEE Transactions on Parallel and Distributed Systems},
  volume = {34},
  number = {12},
  pages = {3253--3265},
  issn = {1558-2183},
  doi = {10.1109/TPDS.2023.3324934},
  urldate = {2023-11-21},
  abstract = {Deep Convolutional Neural Networks (CNNs) are the most widely used family of machine learning methods that have had a transformative effect on a wide range of applications. Previous studies have made great breakthroughs in accelerating CNNs, but they only target on the input sparsity of activation and weight, thus do not eliminate the unnecessary computations due to the fact that more zeros in the output results are not directly caused by the zero-valued positions of the input data. In this paper, we take advantage of the output activation sparsity to reduce the execution time and energy consumption of CNNs. First, we propose an effective prediction method that leverages the output activation sparsity. Our method first predicts the output activation polarity of convolutional layers based on the singular value decomposition (SVD) approach. Then, it uses the predicted negative value to skip invalid computations. Second, an effective accelerator is designed to take advantage of sparsity to achieve CNN inference acceleration. Each PE is equipped with a prediction unit and a non-zero value detection unit to remove invalid computation blocks. And an instruction bypass technique is proposed which further exploits the sparsity of the weights. The efficient dataflow graph mapping approach and pipeline execution ensure high computational resource utilization. Experiments show that our approach achieves up to 1.63{\texttimes} speedup and 55.30\% energy reduction compared with dense networks with a slight loss of accuracy. Compared with Eyeriss, our accelerator achieves on average 1.31 {\texttimes} performance improvement and 54\% energy reduction. Our accelerator also achieves a similar performance to SnaPEA, but with a better energy efficiency.},
  file = {/Users/liutianyu/Documents/Amy's Library/AMS/Fan et al_2023_Accelerating Convolutional Neural Networks by Exploiting the Sparsity of Output_IEEE Transactions on Parallel and Distributed Systems.pdf;/Users/liutianyu/Zotero/storage/WRC2BXPY/authors.html}
}

